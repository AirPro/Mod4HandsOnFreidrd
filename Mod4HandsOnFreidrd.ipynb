{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AirPro/Mod4HandsOnFreidrd/blob/main/Mod4HandsOnFreidrd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZIgCzNiVX7b"
      },
      "source": [
        "# Module 4 Hands On Traffic Sign Assignment\n",
        "By: Robert Freid for the Deep Learning Mod 4 Assignment\n",
        "## Mount the Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sqqJvCMbrA7u",
        "outputId": "237e48dc-1220-4ab0-ced1-acc9e520155e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drsOAdOKrpyB"
      },
      "source": [
        "### Mounting Google Drive Notes\n",
        "Drive already mounted at /content/drive; <br>\n",
        "To attempt to forcibly remount call: <br>\n",
        "drive.mount('/content/drive',force_remout=True)\n",
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LiMETGa9sNeV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt # to plot accuracy\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from PIL import Image # to read image data\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split # to split training and testing data\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8RKjjJfuRGI"
      },
      "source": [
        "## Read the images and save them and their corresponding labels in lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-U-6qLHkuZVr"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "labels = []\n",
        "classes = 43\n",
        "\n",
        "# Copied Path: /content/drive/MyDrive/TrafficSignsData/myData\n",
        "\n",
        "cur_path = \"/content/drive/MyDrive/TrafficSignsData/myData\"\n",
        "\n",
        "# Retreiving the images and their labels\n",
        "\n",
        "for i in range(classes):\n",
        "  path = os.path.join(cur_path,str(i))\n",
        "  images = os.listdir(path)\n",
        "  for a in images:\n",
        "    try:\n",
        "      image = Image.open(path + '/' + a)\n",
        "      image = image.resize((32, 32))\n",
        "      image = np.array(image)\n",
        "      data.append(image)\n",
        "      labels.append(i)\n",
        "    except:\n",
        "      print('Error Loading Image')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzvHDgPNDq2b"
      },
      "source": [
        "## Save the data and labels as numpy arrays\n",
        "## Divide training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQyheShBDz7k"
      },
      "outputs": [],
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)\n",
        "print('Data.shape')\n",
        "print(data.shape)\n",
        "print('Labels.shape')\n",
        "print(labels.shape)\n",
        "\n",
        "# Splitting training and testing data\n",
        "\n",
        "X_train, X_test, y_train, y_test= train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "print('train_test_split results')\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0jqbH5GIc9i"
      },
      "source": [
        "## One hot encodng for labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXGq_Zy7IjBU"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn1BAtYFNKfv"
      },
      "source": [
        "## Define the Deep Learning Model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZTXuRWeNOOj"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(filters=32, kernel_size=(5,5), activation='relu', input_shape=(32,32,3)))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(Dropout(rate=0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(rate=0.5))\n",
        "model.add(Dense(43, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gmE5jh4cFO5"
      },
      "source": [
        "## Show the Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42tmu675cHiJ"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGMaZU2Ne02F"
      },
      "source": [
        "## Plot the Model Diagram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQawbAIse3Rl"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "plot_model(model, to_file='model_plot.png', dpi=50,show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29P05zz3gHUp"
      },
      "source": [
        "## Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xygCLeTtgJZW"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI_e7jFog-sg"
      },
      "source": [
        "## Set Batch size and number of Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAidLiFnhCWJ"
      },
      "outputs": [],
      "source": [
        "epochsNum = 10\n",
        "batchSize = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kn1VWgdLhMOW"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlAI8sH0hQDR"
      },
      "outputs": [],
      "source": [
        "history=model.fit(X_train, y_train, epochs=epochsNum, batch_size=batchSize, validation_split=0.1, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX9AI4cU04BC"
      },
      "source": [
        "## Train versus Validation Training Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSlUUCo5083C"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train', 'validation'], loc='upper right', fontsize='large')\n",
        "plt.ylabel('loss', fontsize=16)\n",
        "plt.xlabel('epoch', fontsize=16)\n",
        "plt.yticks()\n",
        "plt.xticks(np.arange(0, epochsNum))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdK1vXTg2yGE"
      },
      "source": [
        "## Train versus Validation Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQFg1TCy21Pi"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.xlabel('epoch', fontsize=16)\n",
        "plt.ylabel('accuracy', fontsize=16)\n",
        "plt.yticks(np.arange(0.0, 1.05, 0.1))#, step=0.5))\n",
        "plt.xticks(np.arange(0, epochsNum))# +1 )) step=10))\n",
        "plt.legend(['train', 'validation'], loc='lower right', fontsize='large')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_ClrNW478yU"
      },
      "source": [
        "## Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtHEC5Q67_A1"
      },
      "outputs": [],
      "source": [
        "pred_test = model.predict(X_test)\n",
        "y_pred = pred_test.round()\n",
        "scores2 = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Accuracy on test data: {}% \\n Error on test data: {}'.format(scores2[1], 1 - scores2[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwyZAFreOK_k"
      },
      "source": [
        "## Decode the One Hot Encoder back to Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u_lc0DbOQln"
      },
      "outputs": [],
      "source": [
        "decoded_y_test = tf.argmax(y_test, axis=1)\n",
        "decoded_prediction = tf.argmax(pred_test, axis=1)\n",
        "\n",
        "print(decoded_y_test.shape)\n",
        "print(decoded_prediction.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsgL0v6TOwhd"
      },
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wBEkSTsOzHs"
      },
      "outputs": [],
      "source": [
        "tf.math.confusion_matrix(decoded_y_test, decoded_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7mzWgY6PDu2"
      },
      "source": [
        "## Confusion Matrix using Seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sa-etGY1PHz9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sn\n",
        "\n",
        "cm = confusion_matrix(decoded_y_test, decoded_prediction)\n",
        "\n",
        "sn.heatmap(cm,annot=True) # fmt='d', xticklabels=labels[name],yticklabels=labels['name], cbar=False\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title(\"Confusion Matrix\", fontsize=10)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1x_SKeRLoy_dUqfEUxUwLyS9E9R1VTU-s",
      "authorship_tag": "ABX9TyO/Xz+8em7uxrryR51NIu+r",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}